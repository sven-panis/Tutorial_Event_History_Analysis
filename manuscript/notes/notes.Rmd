---
title: "notes"
author: "Rich"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---

# June 20th 2025 #

## package loading ##

loading packages at the top of the file is a bit of a mess at the minute and appears rather complicated and it needs cleaning up.
there are several repeat library loads e.g., tidyverse and patchwork

-> I removed redundant packages.

## r-references ##

this bib r-references r-ref thing file prevented the manuscript from building, so I had to comment it out.
This needs fixing.

-> I got it working but packages are (for now) mentioned in text instead of in footnote...


## intro ##

- I made the intro shorter. We still make the same points, just in far fewer words.

-> Well done!

## section 2 ##

I took out the following and changed it to be far shorter. 
If you want to include any of it in supps, then let's discuss it.

-> Section A of the revised Suppl. Material now contains the Figure of RT tasks and discussion of the types of time-to-event data obtained in typical RT tasks.



Instead, I chose to focus on picking out the benefits of EHA for research in experimental psychology.
That way, we are being explicit about what we are aiming to do in this section.
And we are therefore making it clear that we are NOT providing a detailed description of EHA.
There is simply not enough space.
And we look confused and contradictory because we don't actually do what we say. 

You will notice that I have mentioned many of the below points, just not in detail.
And again, that's becuase that is not the point of the paper. 

- leave the survivor function in supps because it just seems unnecessary, especially since we do not plot it anymore.


-> I agree.


- Sven - can you add a relevant reference for the following statement:
Statisticians and mathematical psychologists recommend focusing on the hazard function when analyzing time-to-event data for various reasons (REF??).

-> Done.

- in section 2.3 can you add a line or two about bin width please?

-> Done.

<!-- ## 2.1 Single, repeatable, and recurrent events -->

<!-- While people can die only once, in experimental RT tasks the events of interest are typically repeatable. For example, in the target-present condition of a one-button detection task the participant is presented in each trial with a faint target stimulus whose presence (s)he has to detect by pressing a button within a certain time window (e.g., the first second after target onset). In EHA parlance, the single event of interest is a button press response, *time zero* is defined as target display onset, the  *observation period* is 1 second long in each trial or repeated measurement, in each trial the participant is *at risk* for response occurrence as long as the response has not occurred yet, and the individual always starts in an "idle" state in each trial and *transitions* to a "detected" state when a response occurs. -->

<!-- In a two-button discrimination task, the participant is presented in each trial with a target stimulus that (s)he has to categorize by pressing one of two buttons within a certain time window. In the world of EHA, this is known as a "competing risks" situation, because in each trial the participant can transition from an idle state to either a "correct response" state or an "incorrect response" state. -->

<!-- In a bistable perception task, the participant is looking at an ambiguous stimulus (e.g., the duck-rabbit illusion, the Necker cube) for two minutes, for example, and asked to press a button each time when her/his perception switches from one possibe interpretation to the other possible interpretation. In this task, there are two events (percept A switches to percept B, percept B switches to percept A) that can recur within the same observation period of two minutes, so that the individual transitions back and forth between two states.  -->

<!-- In section A of the Supplemental Material we visualize the types of time-to-event data that are obtained in these typical RT tasks (detection, discrimination or categorization, bistable perception). Note that we do not analyse recurrent events in this tutorial. More information about recurrent events analysis can be found in REF and REF... -->

<!-- ## 2.2 Right censoring versus data trimming -->

<!-- What do you do with trials in which no response occurs during the observation period? EHA treats such trials as *right-censored* observations on the variable RT, because all we know is that RT is greater than some value. Right-censoring is a type of missing data problem and a nearly universal feature of survival data including RT data. For example, in the one-button detection task example from above, all trials have a *censoring time* of 1 second, but some trials result in observed event times (those with a RT below 1 second), while the other trials result in response times that are right-censored at 1 second.  -->

<!-- EHA can deal in a straight-forward fashion with right-censored time-to-event data. In contrast, experimental psychologists are used to either (a) use a response deadline and discard all trials without a response, or (b) wait in each trial until a response occurs and then apply data trimming techniques, i.e., discarding too short or too long RTs before calculating a mean RT (REF). Discarding data can introduce biases, however.  -->

<!-- ## 2.3 Discrete vs continuous time units -->

<!-- All man-made measurements of duration are discrete in nature. However, when the temporal resolution is high relative to the duration of the observation window, researchers typically treat time as continuous. RT data can thus be analysed using continuous-time EHA methods which use the exact event times, including parametric models (e.g., an exponential hazard model, a Weibull hazard model, a lognormal hazard model) and the popular Cox regression model (). -->

<!-- However, in this tutorial we focus on discrete-time methods for three reasons: -->
<!-- First, we are interested in studying the shape of the hazard function (Cox regression ignores this and only tests the effects of covariates);  -->
<!-- Second, empirical hazard and conditional accuracy functions from certain RT tasks (e.g., interference tasks; Figure 1B) can show abrupt changes in their shape (parametric methods assume smooth distributions), and the shape of the hazard function in many experimental tasks is still unknown (parametric methods assume well-defined probability distributions); -->
<!-- Third, in discrete time, hazard is simply defined as a conditional probability (see 2.4) and we can apply logistic regression modeling with which most experimental psychologists are already familiar. -->

<!-- In sum, due to their simplicity and flexibility, we believe that discrete-time methods are a good starting point for experimental psychologists that want to abandon ANOVA and learn to apply EHA, even though continuous-time methods might be more suited in certain situations. -->

<!-- ## 2.4 Discrete-time hazard functions and conditional accuracy functions -->

<!-- After dividing time in discrete, contiguous time bins indexed by t (e.g., t = 1:10 time bins; Figure 1B), let RT be a discrete random variable denoting the *rank* of the time bin in which a particular person's response occurs in a particular experimental condition. For example, the detection response in trial 1 might occur at 546 ms and it would be in time bin 6 (any RTs from 501 ms to 600 ms). Thus, the RT data are interval-censored, because we only use the information that a<RT<=b when the response occurs in time bin (a,b]. -->

<!-- While experimental psychologists are familiar with the cumulative distribution function or F(t) = P(RT <= t) and the probability mass function or P(t) = P(RT = t), discrete-time EHA focuses on the discrete-time hazard function of event occurrence: -->

<!-- \noindent h(t) = P(RT = t| RT $\geq$ t)   \hfill  (1) -->

<!-- \noindent and the discrete-time survivor function:  -->

<!-- \noindent S(t) = P(RT $>$ t) = 1 - F(t) =  [1-h(t)].[1-h(t-1)].[1-h(t-2)]...[1-h(1)]  \hfill  (2) -->


<!-- The discrete-time hazard function gives you, for each time bin, the conditional probability that the event occurs (sometime) in bin t, given that the event does not occur in previous bins.  -->
<!-- In other words, it reflects the instantaneous risk that the response occurs in bin t, given that it has not yet occurred in one of the prior bins. In contrast, the discrete-time survivor function cumulates the bin-by-bin risks of event *non*occurrence to obtain the survival probability, the probability that the event does not occur before the endpoint of bin t. As a result, only the hazard function conveys the risk of event occurrence associated with each bin, and ... suited for online tracking of performance.. cfr mouse cursor movements.... -->

<!-- For two-choice RT data, the discrete-time hazard function can be extended with the discrete-time conditional accuracy function  -->

<!-- \noindent ca(t) = P(correct | RT = t)   \hfill  (5) -->

<!-- \noindent which gives you for each bin the probability that a response is correct given that it is emitted in time bin t [@kantowitzInterpretationReactionTime2021; @wickelgrenSpeedaccuracyTradeoffInformation1977; @allisonSurvivalAnalysisUsing2010]. The ca(t) function is also known as the micro-level speed-accuracy tradeoff (SAT) function. -->
<!-- We refer to this extended (hazard + conditional accuracy) analysis for choice RT data as EHA/SAT.  -->

<!-- As we will illustrate in Tutorials 1a and 1b, performing a descriptive EHA/SAT analysis by calculating the sample-based estimates of h(t), S(t) and ca(t) for each combination of participant and condition requires setting up a *life table*. -->
<!-- Definition life table... -->



<!-- ## 2.5 Bayesian vs. frequentist approaches to regression -->

<!-- To study how the risk of a response, and the accuracy of an emitted response, depends on covariates (i.e., explanatory predictor variables) we can estimate regression models for hazard and for conditional accuracy, i.e., perform inferential EHA/SAT analysis. Such covariates can be constant over within-trial time (e.g., gender, race, trial number, block number) or vary with within-trial time (e.g., heart rate, eye gaze position, eye pupil dilation). Note that time-varying covariates are not covered in this tutorial. -->

<!-- Heterogeneity -> Multilevel survival analysis: Methods, Models and Applications -->
<!-- Austin 2017 !! -->


<!-- fitting problems -> Bayesian -->


<!-- ## 2.6 Number of samples, repeated measures, time bins -->

<!-- In a typical RT data set from a within-subject design, there are N individuals and M repeated measures or trials per experimental condition. -->
<!-- To test process models of cognition, .. advises  to use small-N designs, ... eACH SUBJECT REPLICATION UNIT -->

<!-- Power IS A COMPLEX FUNCTION OF .... (REF A, REF B ON POWER WITH EXPONENTIAL) -->

<!-- Number of time bins? -->

<!-- bin width -->
<!-- ------------------- -->


## tutorial section ##

- the frequentist tutorial still needs removing and placing in supps. 
then just refer to it in the main text.
I commented it out for now.

-> Done.

## 4.1.2 ##

please move the below text to the script or tutorial itself.
e.g., inlcude a commented out note that explains this can be ignored.
there is no need for this in the paper itself.

<!-- When creating the plots, some warning messages will likely be generated, like these: -->

<!-- * Removed 2 rows containing missing values or values outside the scale range (`geom_line()`).  -->
<!-- * Removed 2 rows containing missing values or values outside the scale range (`geom_point()`).  -->
<!-- * Removed 2 rows containing missing values or values outside the scale range (`geom_segment()`). -->

<!-- The warning messages are generated because some bins have no hazard and ca(t) estimates, and no error bars. They can thus safely be ignored. -->


-> Done.

page 19. Figure 2. The image warped / wrong size and needs fixing.

-> Done.


## combining figures ##

we currently have a lot of space dedicated to results figures e.g., Figures 3,4,5,6,7,8.

I suggest an alternative, which is more efficient and compact.

Let's at least try it and see how we think it compares. 

I would reduce 6 figures into 2.

One hazard figure.

One ca figure.

Each figure has 3 panels across 3 rows.
panel a - parameter estimates (current figure 3 e.g.)
panel b - predicted hazard group level (current figure 4a)
panel c - condition differences in hazard (current figure 5a).

Then do the same for CA in a separate figure.

And then report individual differences in Supplementary and refer to the figure in the main text.

What I like about this approach is that:

A) we save a tremendous amount of space.
B) we still make the same points.
C) we do not really focus in any material way on individual differences, so why both with the plots in the main text.
D) folks still have easy access to the code and the plots in Supps should they feel they need them.
E) we are really responding well to reviewers in terms of saving space and being more compact.

-> TODO.

## discussion ##

I removed the unnecessary sections that we discussed previously.

-> ok.


# June 30th 2025 #

## section 1.1 ##

- re-combine paragraphs 2 and 3. That way, you don't start a paragraph with "For example ..."

-> Done. I separated them before to avoid an almost blank page in the ms...

## section 2.3 ##

- para 2. 1 sentence is not a paragraph. is this not finished yet? I don't understand hopw that sentence fits.

-> Changed.

## response to reviewers ##

- the formatting really helps distinguish between editor/reviewer comments and our responses. Nice one. it is so much easier to read.

-> I agree.



- the below quote is not contradictory, but it sure sounds it. Can we rework it? Do you see what I mean? single events that repeat... Maybe just an extra sentence or two to make the relevant distinction clear.

>Response: On page 7 of the revised ms., we mention that we measure single-event occurrences that are repeatedly measured in each participant.

-> This sentence has been removed. I added this sentence: "These minimal requirements are fulfilled by the RT data obtained in single-button detection tasks, where the time-to-response is repeatedly measured in different trials in the same individual. In section A of the Supplemental Material we visualize this and other types of time-to-event data which are typically obtained in discrimination and bistable perception tasks."
Thus, based on section A in the Supplemental Material, the distinction between single event and repeated events should be clear now.



on line 510 of the response, you say:

>Response: We provided a clearer description of the data.

I think it is essential to always provide page, para and/or line numbers for reviewers so that they can easily check things. This same logic should be applied to all of our responses where necessary. Once the page numbers change, it can be a nightmare to find and verufy changes as a reviewer.

-> I agree.


# July 7th 2025 #

## repsponse document ##

-page 2. we say:
>It also visualizes recurrent events and includes the Lougheed and Stoolmiller tutorials.

Do we mean "includes reference to the Lougheed and Stoolmiller tutorials"? If not, it is a little odd to read. 

-> corrected.



-page 6. we say this, which is a direct quote from the manuscript:

>“... because multilevel generalized linear regression models often do not converge with complex
random-coefficient structures, we do not discuss them here.”

I also read this in the main text for context. 
It doesn't make sense as it is written in the main text, so let's move it to supps.
Instead, in the main text, let's just say this.

> Finally, because many researchers will be more familiar with frequentist statistics, we also provide code to fit hazard and conditional accuracy models in the frequentist framework using the R package lme4() (see Tutorial_3a.Rmd and Tutorial_3b.Rmd). 

If we have anything more elaborate to say about model fitting etc., then let's say it in the tutorial/s.

And in the response to the reviewer, let's NOT say "We have no idea why the models did not converge ..."
Instead, let's say it is common for models to fail to converge in lme4 when they have a reasonably complex random effects structure. (We can also say this in the tutorial or supps, as necessary).

-> Done.

And then can we cite the lme4 tutorial paper or something else to provide a resource for folks to use?

The idea would be that (1) all frequentist stuff is in supps and (2) we provide a reference for others to follow. 

-> I added a reference.


-page 16 of the review. Page 28 of the main manuscript.

>To make causal inferences...

Was this language in the original submission? e.g., did we say causal in the original?

-> No we did not. I changed this to make a distinction between model prediction (for the model comparison section) and model inference.



If we want to keep this language, can we cite the following textbook (see below)? 
It has a really nice section on the link between experimental designs and causal inferences. 
We don't need to say anything else, just insert the reference.

https://experimentology.io/

Frank, M. C., Braginsky, M., Cachia, J., Coles, N. A., Hardwicke, T. E., Hawkins, R. D., Mathur, M. B., & Williams, R. 2025. Experimentology: An Open Science Approach to Experimental Psychology Methods. Stanford University. https://doi.org/10.25936/3JP6-5M50. (Also published by MIT Press, ISBN 978-0-262-55256-1)

BibTex:

@book{experimentology2025,
  author    = {Frank, Michael C. and Braginsky, Mika and Cachia, Julie and Coles, Nicholas A. and Hardwicke, Tom E. and Hawkins, Robert D. and Mathur, Maya B. and Williams, Rondeline},
  title     = {{Experimentology: An Open Science Approach to Experimental Psychology Methods}},
  year      = {2025},
  publisher = {Stanford University},
  doi       = {10.25936/3JP6-5M50},
  note      = {Also published by MIT Press, ISBN 978-0-262-55256-1}
}

-> I added this reference to the ms.


## manuscript ##

-page 11. The below sentence:

>First, one can use a response deadline in each trial because EHA deals with right-censored observations.

This still needs explaining/contextualising with an extra sentence or two. It does not stand alone as it is currently written.

-> Done.


# July 9th #

## manuscript ##

- figure 1 legend. 

write out EHA/SAT in full. At this stage, these terms have not been defined, so using abbreviations is meaningless. Or just remove the labels completely and say " ... versus a distributional analysis". 

-> EHA/SAT has been removed.


the brackets are wrong in the Figure 1 legend. (0,100]. This should be [0,100], right? This happens twice.

-> No this was correct. I changed it again.



- page 6. first para. EHA is not defined in the main text yet, but we use the abbreviation. We cannot do this. And int he response, don't we say that we are not doing this? This becomes very confusing and incoherent. We have to define any abbreviations we use at their first instance in the main text.

One option would be to add a line on page 3 para 2, like this:

...compared to the aggregation of data across trials (Figure 1A), a distributional approach known as event history analysis (EHA) offers ...

If not here, we need it somewhere else. This is really basic and needs to done consistently.


-> Because previous reviewers saw SAT as a separate analysis than EHA, I am reluctant to say "Indeed, compared to the aggregation of data across trials (Figure 1A), a distributional approach known as event history analysis (EHA)
offers the possibility to reveal the time course of psychological states (Figure 1B)" as this implies that Figure 1B is an EHA.
Instead, I added this sentence: "Here we apply a distributional method known as event history analysis (EHA) extended with speed-accuracy tradeoff (SAT) analysis."






- page 13. tutorials. I would get rid of all of the package references to ease the flow of reading. Can they go in supplementary materials? Or somewhere else? At the moment, it isn't working with them piled into a massive paragraph.

-> I put them back in a footnote. I like it this way. Let me know if you want them in an extra section in the Suppl. Material...



- page 19. delete the sentence below, as we already say that earlier in the manuscript:

>Too small bin widths...

-> I cannot find this sentence...??



- Figure 3. Can you make the figure longer? It looks squashed and is hard to see/understand. If it takes up the whole page and the legend goes off the page, then that's ok. Same goes for Figure 4 also. 

-> Done. When the figure gets too large the caption goes off the page without appearing on the next page... I have to see how this can be solved.


- Figures 3 and 4. The colours are wrong in panel C. This is really confusing. We need to set the colours to be consistent. e.g., if congruent is orange on A and B, it should be orange in C. To do so, in the code for panel C, you need to use scale_fill_manual(values=c("#D95F02FF", "#7570B3FF")). ANd then choose the relevant hex codes e.g., https://emilhvitfeldt.github.io/r-color-palettes/discrete/RColorBrewer/Dark2/index.html.

Does this make sense? It is really important. Please check the colour codes are correct.


-> I changed the colors.


- page 33. para 2. We need to cite Bates et al., 2015 for the lme4 package.

-> Done.


- in the manuscript.Rmd file, can we delete all text that we are not keeping? It seems really untidy/annoying to have loads of text commented out. Does this make sense? Just delete it and commit the change. I already deleted some stuff, but there is more to do maybe?


->  Done.


- Just quickly, one thing I noticed, which seems strange, is that we have 6 reference files (.bib files). Some of them are repeats - is this intentional? It seems very strange and a recipe for confusion and difficulty reproducing our workflow. In some cases, I can see the need - e.g., supps or tutorial refs that are separate. But then why do we have things like extrarefernces and extrareferneces2? I really think we should clean this up, so that we have one reference file per document. If we need a separate r-reference file for the manuscript then that’s fine. 
Can you explain the need or make them more efficient?

-> I explain their needs in README: extrareferences are manually selected references (not in Zotero); extrareferences2.bib is created by exporting a library from Zotero.

