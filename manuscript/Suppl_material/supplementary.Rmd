---
title             : no
shorttitle        : "A tutorial on event history analysis"
bibliography      : ["extrareferences2.bib"]
floatsintext      : yes
linenumbers       : yes
draft             : no
mask              : no
figurelist        : no
tablelist         : no
footnotelist      : no
classoption       : "man"
output            : papaja::apa6_pdf
editor_options: 
  chunk_output_type: console
header-includes:
  - \raggedbottom
---

```{r setup, include = FALSE}
pkg <- c("papaja", "citr", "tidyverse", "RColorBrewer", "patchwork")

lapply(pkg, library, character.only = TRUE)
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

```{r plot-settings}
## theme settings for ggplot
theme_set(
  theme_bw() +
    theme(text = element_text(size = 18, face = "bold"), 
          title = element_text(size = 18, face = "bold"),
          legend.position = "bottom")
)

## Set the amount of dodge in figures
pd <- position_dodge(0.7)
pd2 <- position_dodge(1)
```

```{r global-chunk-settings}
## set the figure options
knitr::opts_chunk$set(fig.pos='H', out.extra = '', out.height = "67%",
                      fig.align = "center") # initial version
```

<!-- the below two lines directly change the default Figure and Table naming to Supplementary -->

<!-- see here for more details - https://stackoverflow.com/questions/47173279/internationalization-r-knitr-figure-caption-label -->

\renewcommand{\figurename}{Supplementary Figure}
\renewcommand{\tablename}{Supplemetentary Table}

# Supplemental Material

## A. RT tasks in the context of EHA: right-censoring versus random censoring

While people can die only once, in experimental RT tasks the events of interest are typically repeatable. In Supplementary Figure 1A, we present a hypothetical single-subject RT data set from a detection experiment with one response button and two experimental conditions: target present and target absent. For example, each trial in each condition might start with a fixation screen for 1 s, followed by a blank screen for 1 s, a target display screen for 100 ms in which the target stimulus is presented or not depending on the experimental condition the trials belongs to, and finally a blank screen until an overt response is detected or 500 ms have passed. Supplementary Figure 1A shows the typical pattern: the participants presses the button sometime before 500 ms in most trials in the target-present condition (black dots), while (s)he does not press the button in most trials of the target-absent condition (black crosses). 

In EHA parlance, the single event of interest is a button press response, *time zero* is defined as target display onset, the  *observation or follow-up period* is 500 ms long in each trial or repeated measurement, in each trial the participant is *at risk* for response occurrence as long as the response has not occurred yet, the individual starts in an "idle" state in each trial and *transitions* to a "detected" state when a response occurs, all trials have a censoring time of 500 ms, and some trials result in observed event times (those with a RT below 500 ms), while other trials result in response times that are right-censored at 500 ms. 

Right-censoring occurs when we only know that the event time is larger than some value, i.e., the censoring time. The most common type of right-censoring is “singly Type I censoring” which applies when the experiment uses a fixed response deadline for all trials. “Type I” means that the censoring time is fixed and under the control of the experimenter; “Singly” refers to the fact that all observations have the same censoring time (Allison, 2010). Clearly, discarding right-censored observations before calculating the median or mean RT will result in biased estimates, especially in the target-absent condition. 

(ref:descr-plot-RT-tasks-caption) RT tasks and EHA concepts. The timer starts at time 0 (black vertical line) and ends at the censoring time (dotted vertical line). In each trial of each condition of each task, an overt response time (RT) is indicated by a circle. (A) Single-button detection data requires a single-event analysis. (B) Two-button discrimination data requires a competing risks analysis. (C) Competing risk data in combination with an stimulus-onset-asynchrony manipulation might require increasing the observation period in each trial. (D) Two-button bistable perception data requires a recurrent event / multistate analysis. Black bars indicate stimlus presentation.

```{r plot-RT-tasks, fig.cap = "(ref:descr-plot-RT-tasks-caption)", out.width="80%"}
knitr::include_graphics("../../manuscript/Suppl_material/Plot_paradigms.png")
```

Importantly, when estimating the shape of the RT distribution in each experimental condition, EHA takes into account right-censored observations. As a result, EHA has a wider scope than current methods, as it can also be applied to RT data from experimental paradigms in which RTs are typically not measured, such as masking experiments and studies on the attentional blink. Also, EHA allows to increase experimental design efficiency, because we can introduce a response deadline instead of waiting until a response is emitted in each trial, so that we do not have to wait for very slow responses which would be trimmed anyway.

There are different types of censoring. Left censoring occurs when all that is known about an observation on a variable T is that it is less than some value. Interval censoring combines right and left censoring so that all you know about T is that a < T < b, for some values of a and b (Allison, 2010). Random censoring occurs when observations are terminated for reasons that are not under the control of the experimenter. 

In Supplementary Figure 1B, we present a hypothetical single-subject RT data set from a discrimination experiment with two response buttons and two experimental conditions: A and B. For example, each trial in each condition might start with a fixation screen for 1 s, followed by a blank screen for 1 s, a target display screen for 100 ms in which a female or male face is presented, and finally a blank screen until an overt response is detected or 800 ms have passed. Participants are required to press the left button when identifying a male, and the right button when identifying a female. In Supplementary Figure 1B, correct responses are indicated with black dots, error responses with white dots, and the few right-censored observations with crosses.

In EHA parlance this is known as a *competing risks* situation, because from target display screen onset (time zero) onwards, both correct and incorrect responses are competing with another in each trial until one occurs which determines the event type and latency that are recorded. In other words, in each trial the participant can transition from an idle state to either a "correct response" state or an "incorrect response" state.

There are two ways to deal with a competing-risks situation. One approach is to model the hazard function of correct response occurrence and treat incorrect responses as right-censored observations, and vice versa. When estimating the hazard of correct response occurrence, then the unpredictable error responses will introduce random censoring (and vice versa). Importantly, all statistical methods for time-to-event data require that random censoring be noninformative: a trial that is censored at time c should be representative of all those trials with the same values of the explanatory variables that survive to c (Allison, 2010). However, the random censoring by errors when estimating the hazard function of correct responses (and vice versa) is very likely informative, because response channels are known to compete with one another (Burle et al., 2004; Eriksen et al., 1985; Praamstra & Seiss, 2005). Thus, another approach is to model the hazard of (any) response occurrence and extend it with a speed-accuracy trade-off (SAT) analysis (plotting accuracy as a function of latency). This is the approach taken here (see Figure 1), and many experimental psychologists are familiar with SAT.

Studying the effect of stimulus-onset-asynchrony (SOA) on mean RT is still a popular approach to study the time course of cognitive processes. For example, a target stimulus can be presented with a certain SOA in relation to another stimulus (e.g., prime, mask, distractor, cue). However, mean RT conceals the possibe presence of responses triggered by the non-target stimulus (Panis, 2020; Panis & Schmidt, 2016). For example, in Supplementary Figure 1C a prime is presented before a target with a SOA of -400 ms (upper x-axis labels). To capture responses triggered by the prime (and emitted before target onset) we have to start the timer at trial onset. Also, when RTs are originally recorded relative to target onset, we have to add a constant time to each (here: + 400 ms) in order to include these prime-triggered "negative" RTs in the analysis (lower x-axis labels). In general, all RTs must be positive for EHA to work.

Finally, in a bistable perception task (Supplementary Figure 1D), the participant is looking at an ambiguous stimulus (e.g., the duck-rabbit illusion, the Necker cube) for two minutes in each trial, for example, and asked to press a button each time when her/his perception switches from one possibe interpretation to the other possible interpretation. In this task, there are two events (percept A switches to percept B, percept B switches to percept A) that can recur within the same observation period of two minutes, so that the individual transitions back and forth between two states. Note that we do not analyse recurrent events in this tutorial. More information about recurrent events analysis can be found in @stoolmillerModelingHeterogeneitySocial2006, @millsIntroducingSurvivalEvent2011, and @lougheedMultilevelSurvivalAnalysis2019.

## B. Definitions of discrete-time hazard, surivor, probability mass, and conditional accuracy functions

The shape of a distribution of waiting times can be described in multiple ways [@luceResponseTimesTheir1991]. After dividing time in discrete, contiguous time bins indexed by t, let RT be a discrete random variable denoting the rank of the time bin in which a particular person's response occurs in a particular trial. 
Because waiting times can only increase, discrete-time EHA focuses on the discrete-time hazard function 

\noindent h(t) = P(RT = t| RT $\geq$ t)   \hfill  (1)

\noindent and the discrete-time survivor function 

\noindent S(t) = P(RT $>$ t) = [1-h(t)].[1-h(t-1)].[1-h(t-2)]...[1-h(1)]  \hfill  (2)

\noindent and not on the probability mass function 

\noindent P(t) = P(RT = t) = h(t).S(t-1)  \hfill  (3)

\noindent nor the cumulative distribution function 

\noindent F(t) = P(RT $\leq$ t) = 1-S(t)   \hfill  (4)  

The discrete-time hazard function of event occurrence gives you for each bin the probability that the event occurs (sometime) in that bin, given that the event has not occurred yet in previous bins. This conditionality in the definition of hazard is what makes the hazard function so diagnostic for studying event occurrence, as an event can physically not occur when it has already occurred before. 

While the discrete-time hazard function assesses the unique risk of event occurrence associated with each time bin, the discrete-time survivor function cumulates the bin-by-bin risks of event *non*occurrence to obtain the probability that the event does not occur before the endpoint of bin t. 

The probability mass function cumulates the risk of event occurrence in bin t with the risks of event nonoccurrence in bins 1 to t-1. From equation 3 we find that hazard in bin t is equal to P(t)/S(t-1). 

The survivor function provides a context for the hazard function, as S(t-1) = P(RT > t-1) = P(RT $\geq$ t) tells you on how many percent of the trials the estimate h(t) = P(RT = t| RT $\geq$ t) is based. The probability mass function provides a context for the conditional accuracy function, as P(t) = P(RT = t) tells you on how many percent of the trials the estimate ca(t) = P(correct | RT = t) is based.

For two-choice RT data, the discrete-time hazard function can be extended with the discrete-time conditional accuracy function 

\noindent ca(t) = P(correct | RT = t)   \hfill  (5)

\noindent which gives you for each bin the probability that a response is correct given that it is emitted in time bin t [@kantowitzInterpretationReactionTime2021; @wickelgrenSpeedaccuracyTradeoffInformation1977; @allisonSurvivalAnalysisUsing2010]. The ca(t) function is also known as the micro-level speed-accuracy tradeoff (SAT) function.



While psychological RT data is typically measured in small, continuous units (e.g., milliseconds), discrete-time EHA treats the RT data as interval-censored data, because it only uses the information that the response occurred sometime in a particular bin of time (x,y]: x < RT $\leq$ y. If we want to use the exact event times, then we treat time as a continuous variable, and let RT be a continous random variable denoting a particular person's response time in a particular trial. Continuous-time EHA does not focus on the cumulative distribution function F(t) = P(RT $\leq$ t) and its derivative, the probability density function f(t) = F(t)', but on the survivor function S(t) = P(RT $>$ t) and the hazard rate function $\lambda$(t) = f(t)/S(t). The hazard rate function gives you the instantaneous *rate* of event occurrence at time point t, given that the event has not occurred yet. Models for continous-time event data come in three forms: parametric models, Cox regression, and piece-wise exponential models [@singerAppliedLongitudinalData2003].

## C. Custom functions for descriptive discrete-time hazard analysis

We defined 12 custom functions that we list here. 

* censor(df,timeout,bin_width) : divide the time segment (0,timeout] in bins, identify any right-censored observations, and determine the discrete RT (time bin rank)
* ptb(df) : transform the person-trial data set to the person-trial-bin data set
* setup_lt(ptb) : set up a life table for each level of 1 independent variable
* setup_lt_2IV(ptb) : set up a life table for each combination of levels of 2 independent variables
* calc_ca(df) : estimate the conditinal accuracies when there is 1 independent variable
* calc_ca_2IV(df) : estimate the conditional accuraies when there are 2 independent variables
* join_lt_ca(df1,df2) : add the ca(t) estimates to the life tables (1 independent variable)
* join_lt_ca_2IV(df1, df2) : add the ca(t) estimates to the life tables (2 independent variables)
* extract_median(df) : estimate quantiles S(t)~.50~ (1 independent variable)
* extract_median_2IV(df) : estimate quantiles S(t)~.50~ (2 independent variables)
* plot_eha(df, subj, haz_yaxis=1, first_bin_shown=1, aggregated_data=F, Nsubj=6) : create plots of the discrete-time functions (1 independent variable), and specify the upper limit of the y-axis in the hazard plot, with which bin to start plotting, whether the data is aggregated across participants, and across how many participants
* plot_eha_2IV(df, subj, haz_yaxis=1, first_bin_shown=1, aggregated_data=F,   Nsubj=6) : create plots of the discrete-time functions (2 independent variables), and specify the upper limit of the y-axis in the hazard plot, with which bin to start plotting, whether the data is aggregated across participants, and across how many participants

When you want to analyse simple RT data from a detection experiment with one independent variable, the functions calc_ca() and join_lt_ca() should not be used, and the code to plot the conditional accuracy functions should be removed from the function plot_eha().
When you want to analyse simple RT data from a detection experiment with two independent variables, the functions calc_ca_2IV() and join_lt_ca_2IV() should not be used, and the code to plot the conditional accuracy functions should be removed from the function plot_eha_2IV().

## D. Link functions

Popular link functions include the logit link and the complementary log-log link, as shown in Supplementary Figure 2.

(ref:descr-plot14-caption) The logit and complementary log-log (cloglog) link functions.
 
```{r plot-link-functions, fig.cap = "(ref:descr-plot14-caption)", out.width='80%'}
knitr::include_graphics("../../Tutorial_2_Bayesian/figures/linkfunctions.png")
```

## E. Regression equations

An example (single-level) discrete-time hazard model for individual i in bin t of trial j with three predictors (TIME, X~1~, X~2~), the cloglog link function, and a second-order polynomial specification for TIME can be written as follows:

\noindent cloglog[h~ij~(t)] = ln(-ln[1-h~ij~(t)]) =  [$\beta$~0~ONE + $\beta$~1~(TIME-9) + $\beta$~2~(TIME-9)$^2$] +                                    [$\beta$~3~X~1ij~ + $\beta$~4~X~2ij~ + $\beta$~5~X~2ij~(TIME-9)]  \hfill  (6)

The main predictor variable TIME is the time bin index t that is centered on value 9 in this example. The first set of terms within brackets, the parameters $\beta$~0~ to $\beta$~2~ multiplied by their polynomial specifications of (centered) time, represents the shape of the baseline cloglog-hazard function (i.e., when all predictors X~ij~ take on a value of zero). The second set of terms (the beta parameters $\beta$~3~ to $\beta$~5~) represents the vertical shift in the baseline cloglog-hazard for a 1 unit increase in the respective predictor variable. Predictors can be discrete, continuous, and time-varying or time-invariant. For example, the effect of a 1 unit increase in X~1ij~ is to vertically shift the whole baseline cloglog-hazard function by $\beta$~3~ cloglog-hazard units. However, if the predictor interacts linearly with TIME (see X~2ij~ in the example), then the effect of a 1 unit increase in X~2ij~ is to vertically shift the predicted cloglog-hazard in bin 9 by $\beta$~4~ cloglog-hazard units (when TIME-9 = 0), in bin 10 by $\beta$~4~ + $\beta$~5~ cloglog-hazard units (when TIME-9 = 1), and so forth. To interpret the effects of a predictor, its $\beta$ parameter is exponentiated, resulting in a hazard ratio (due to the use of the cloglog link). When using the logit link, exponentiating a $\beta$ parameter results in an odds ratio.

An example (single-level) discrete-time hazard model for individual i in bin t of trial j with a general specification for TIME (separate intercepts for each of six bins, where D1 to D6 are binary indicator variables identifying each bin) and a single predictor (X~1ij~) can be written as follows:

\noindent cloglog[h~ij~(t)] =  [$\beta$~0~D1 + $\beta$~1~D2 + $\beta$~2~D3 + $\beta$~3~D4 + $\beta$~4~D5 + $\beta$~5~D6] + [$\beta$~6~X~1ij~]  \hfill  (7)

## F. Prior distributions

To gain a sense of what prior *logit* values would approximate a uniform distribution on the probability scale, @kurzAppliedLongitudinalDataAnalysis2023 simulated a large number of draws from the Uniform(0,1) distribution, converted those draws to the log-odds metric, and fitted a Student's t distribution. Row C in Supplementary Figure 3 shows that using a t-distribution with 7.61 degrees of freedom and a scale parameter of 1.57 as a prior on the logit scale, approximates a uniform distribution on the probability scale. According to @kurzAppliedLongitudinalDataAnalysis2023, such a prior might be a good prior for the intercept(s) in a logit-hazard model, while the N(0,1) prior in row D might be a good prior for the non-intercept parameters in a logit-hazard model, as it gently regularizes p towards .5 (i.e., a zero effect on the logit scale).

(ref:descr-plot15-caption) Prior distributions for the Intercept on the logit and/or cloglog scales (middle column), and their implications on the probability scale after applying the inverse-logit (or logistic) transformation (left column), and the inverse-cloglog transformation (right column).

```{r plot-priors, fig.cap = "(ref:descr-plot15-caption)", out.width='80%'}
knitr::include_graphics("../../Tutorial_2_Bayesian/figures/plot_of_priors.png")
```

To gain a sense of what prior *cloglog* values would approximate a uniform distribution on the hazard probability scale, we followed Kurz's approach and simulated a large number of draws from the Uniform(0,1) distribution, converted them to the cloglog metric, and fitted a skew-normal model (due to the asymmetry of the cloglog link function). Row E shows that using a skew-normal distribution with a mean of -0.59, a standard deviation of 1.26, and a skewness of -4.22 as a prior on the cloglog scale, approximates a uniform distribution on the probability scale. 
However, because hazard values below .5 are more likely in RT studies, using a skew-normal distribution with a mean of -1, a standard deviation of 1, and a skewness of -2 as a prior on the cloglog scale (row F), might be a good weakly informative prior for the intercept(s) in a cloglog-hazard model. 

## G. Advantages of EHA

Statisticians and mathematical psychologists recommend focusing on the hazard function when analyzing time-to-event data for various reasons. First, as discussed by @holdenDispersionResponseTimes2009, “probability density [and mass] functions can appear nearly identical, both statistically and to the naked eye, and yet are clearly different on the basis of their hazard functions (but not vice versa). Hazard functions are thus more diagnostic than density functions” (p. 331) when one is interested in studying the detailed shape of a RT distribution [see also Figure 1 in @panisAnalyzingResponseTimes2020]. Therefore, when the goal is to study how psychological effects change over time, hazard and conditional accuracy functions are the preferred ways to describe the RT + accuracy data. 

Second, because RT distributions may differ from one another in multiple ways, @townsendTruthConsequencesOrdinal1990 developed a dominance hierarchy of statistical differences between two arbitrary distributions A and B. For example, if h~A~(t) > h~B~(t) for all t, then both hazard functions are said to show a complete ordering. Townsend (1990) concluded that stronger conclusions can be drawn from data when comparing the hazard functions using EHA. For example, when mean A < mean B, the hazard functions might show a complete ordering (i.e., for all t), a partial ordering (e.g., only for t > 300 ms, or only for t < 500 ms), or they may cross each other one or more times.

Third, EHA does not discard right-censored observations when estimating hazard functions, that is, trials for which we do not observe a response during the observation period in a trial so that we only know that the RT must be larger than some value (e.g., the response deadline). This is important because although a few right-censored observations are inevitable in most RT tasks, a lot of right-censored observations are expected in experiments on masking, the attentional blink, and so forth. In other words, by using EHA you can analyze RT data from experiments that typically do not measure response times. Ignoring trials without a response leads to underestimation of the true mean. By introducing a fixed censoring time for all trials, trials with long RTs are not discarded but contribute to the risk set of each bin.

Fourth, hazard modeling allows one to incorporate time-varying explanatory covariates, such as heart rate, electroencephalogram (EEG) signal amplitude, gaze location, pupil dilation, etc. [@allisonSurvivalAnalysisUsing2010]. This is useful for linking physiological effects to behavioral effects when performing cognitive psychophysiology [@meyerModernMentalChronometry1988].

Finally, as explained by @kelsoOutlineGeneralTheory2013, it is crucial to first have a precise description of the macroscopic behavior of a system (here: h(t) and possibly ca(t) functions) in order to know what to derive on the microscopic level. EHA can thus solve the problem of model mimicry, i.e., the fact that different computational models can often predict the same mean RTs as observed in the empirical data, but not necessarily the detailed shapes of the empirical RT hazard distributions. Also, fitting parametric functions or computational models to data without studying the shape of the empirical discrete-time h(t) and ca(t) functions can miss important features in the data, such as short-lived "dips" that could signal the presence of active top-down respone inhibition processes [@panisStudyingDynamicsVisual2020; @panisWhatShapingRT2016]. As such, EHA can be a tool to help distinguish between competing theories of cognition and brain function. 

# References






