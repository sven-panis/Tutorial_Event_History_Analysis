---
title: "Tutorial_2"
author: "Sven Panis"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

In this file we build a Bayesian hazard regression model for the first experiment of Panis and Schmidt (2016) using only the no-mask trials (prime = blank, congruent, or incongruent), and visualize the posterior distributions.

# Load the libraries that we will be using

```{r load-pkg}
pkg <- c("cmdstanr", "standist", "tidyverse", "RColorBrewer", "patchwork", 
         "brms", "tidybayes", "bayesplot", "future", "parallel")

lapply(pkg, library, character.only = TRUE)
```

# Set options. 

```{r set-options}
options(brms.backend = "cmdstanr",
        mc.cores = parallel::detectCores(),
        future.fork.enable = TRUE,
        future.rng.onMisuse = "ignore") ## automatically set in RStudio

supportsMulticore()
detectCores()
```

```{r check-info}
packageVersion("cmdstanr")
devtools::session_info("rstan")
```

# Load the person-trial-bin data set that we saved in Tutorial 1.

```{r load-data}
ptb_data <- read_csv("Tutorial_1_descriptive_stats/data/inputfile_hazard_modeling.csv")
print(ptb_data,n=30)
summary(ptb_data) # 26602 rows: 6 participants, trial, 3 conditions, 15 periods, and event indicator (0/1)
```

# Prepare the data set.

```{r prepare-data}
# select analysis time range: (200,600] with 10 bins (time bin ranks 6 to 15)
ptb_data <- ptb_data %>% filter(period > 5)

# create factor condition, with "blank" as the reference level
ptb_data <- ptb_data %>% mutate(condition = factor(condition, labels = c("blank", "congruent","incongruent")))
summary(ptb_data)

# center discrete TIME (period) on bin 9, and trial on trial 1000
ptb_data <- ptb_data %>% mutate(period_9 = period - 9,
                                trial_c = (trial - 1000)/1000)

# remove unnecessary columns before fitting a model
ptb_data <- ptb_data %>% select(-c(bl,tr,trial,period)) # 12840 obs. of 5 variables
head(ptb_data,n=17)
summary(ptb_data)
# 6 subjects
# condition: blank (6401), congruent (2642), incongruent (3797)
# period_9: -3 to 6
# trial_c: -0.999 to 0.540
```

# Plot the logit and complementary log-log (cloglog) link functions

```{r plot-links}
probability <- (1:99999)/100000
logistic <- function(x) { return( 1/(1+exp(-1*x)) )}
logit    <- function(x) { return( log(x/(1-x)) )}
inverse_cloglog <- function(x) { return( 1-(exp(-1*exp(x))) )}
cloglog         <- function(x) { return( log(-1*log(1-x)) )}

cloglog_prob <- cloglog(probability)
logit_prob <- logit(probability)
dataplot <- cbind(probability,cloglog_prob,logit_prob)

ggplot() +
  geom_hline(yintercept=0, color="white") +
  geom_line(data=dataplot,aes(y=logit_prob,x=probability,colour="logit"),linewidth=1) +
  geom_line(data=dataplot,aes(y=cloglog_prob,x=probability,colour="cloglog"),linewidth=1) +
  scale_color_manual(name = "Link function:", values = c("logit" = "darkblue", "cloglog" = "red")) +
  geom_vline(xintercept = logistic(0), linetype="dotted", linewidth = 0.3) +   
  geom_vline(xintercept = inverse_cloglog(0), linetype="dotted", linewidth = 0.3) +
  annotate("text", x = logistic(0)-.02, y = -6, label = "logistic(0) = 0.5", angle = 90) +
  annotate("text", x = inverse_cloglog(0)+.02, y = -6, label = "inverse_cloglog(0) = 0.6321", angle=90) +
  scale_x_continuous(n.breaks=10, limits = c(0,1), ) +
  labs(x = "Probability",
        y = "logit or cloglog scale") +
  theme(panel.grid = element_blank(),
        axis.text=element_text(size=12),
        axis.title=element_text(size=14),
      #  legend.position="top",
        legend.text = element_text(size=14),
      legend.position = "inside",
        legend.position.inside=c(.2,.75),
      legend.background = element_rect(fill="white") )
```

```{r save-plot-links}
ggsave("Tutorial_2_Bayesian/figures/linkfunctions.png", width = 12, height = 10, dpi = 600)
```

# Visualize different prior distributions on the logit and cloglog scales

To gain a sense of what prior logit values would approximate a uniform distriubution on the probability scale, Solomon Kurz simulated a large number of draws from the Uniform(0,1) distribution, converted those draws to the log-odds metric, and fitted a Student's t model.
Here we do the same for prior cloglog values: simulate a large number of draws from U(0,1), convert them to the cloglog metric, and fit a skew-normal model (due to the asymmetry of the cloglog link function).

## Simulate, convert, and fit



## Visualize prior distributions

```{r}
logistic <- function(x) { return( 1/(1+exp(-1*x)) )}
logit    <- function(x) { return( log(x/(1-x)) )}
invcloglog <- function(x) { return( 1-(exp(-1*exp(x))) )}
cloglog    <- function(x) { return( log(-1*log(1-x)) )}

pr1 <- tibble(prior = rnorm(1e6, mean = 0, sd = 4)) %>%  
  mutate(p = logistic(prior)) %>% 
  ggplot(aes(x = prior)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  annotate(geom="text", x=-13, y=60000, label="N(0,4)",
              color="red", size=6) +
  theme(panel.grid = element_blank())

l1 <- tibble(log_odds = rnorm(1e6, mean = 0, sd = 4)) %>%  
  mutate(p = logistic(log_odds)) %>% 
  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  ggtitle("logistic") +
  theme(panel.grid = element_blank())

c1 <- tibble(cloglog_prob = rnorm(1e6, mean = 0, sd = 4)) %>% 
  mutate(p = invcloglog(cloglog_prob)) %>% 
  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  ggtitle("inverse cloglog")+
  theme(panel.grid = element_blank())


pr2 <- tibble(prior = rnorm(1e6, mean = 0, sd = 2)) %>%  
  ggplot(aes(x = prior)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  annotate(geom="text", x=-6, y=60000, label="N(0,2)",
              color="red", size=6) +
  theme(panel.grid = element_blank())

l2 <- tibble(log_odds = rnorm(1e6, mean = 0, sd = 2)) %>%  
  mutate(p = logistic(log_odds)) %>% 
  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())

c2 <- tibble(cloglog_prob = rnorm(1e6, mean = 0, sd = 2)) %>% 
  mutate(p = invcloglog(cloglog_prob)) %>% 
  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())

# flat prior for logistic
pr3 <- tibble(prior = rt(1e6, df = 7.61)* 1.57) %>%  
  ggplot(aes(x = prior)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  annotate(geom="text", x=-4, y=100000, label="t(7.61)*1.57",
              color="red", size=6) +
  theme(panel.grid = element_blank())

l3 <- tibble(log_odds = rt(1e6, df = 7.61)* 1.57) %>%  
  mutate(p = logistic(log_odds)) %>% 
  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())

c3 <- tibble(cloglog_prob = rt(1e6, df = 7.61)* 1.57) %>% 
  mutate(p = invcloglog(cloglog_prob)) %>% 
  ggplot(aes(x = p)) +
  #geom_histogram(bins = 50) +
  #scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())

# prior to .5
pr4 <- tibble(prior = rnorm(1e6, mean = 0, sd = 1))%>%  
  ggplot(aes(x = prior)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  annotate(geom="text", x=-3, y=60000, label="N(0,1)",
              color="red", size=6) +
  theme(panel.grid = element_blank())

l4 <- tibble(log_odds = rnorm(1e6, mean = 0, sd = 1))%>%  
  mutate(p = logistic(log_odds)) %>% 
  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  geom_vline(xintercept=logistic(0), color="red") +
  theme(panel.grid = element_blank())

c4 <- tibble(cloglog_prob = rnorm(1e6, mean = 0, sd = 1)) %>% 
  mutate(p = invcloglog(cloglog_prob)) %>% 
  ggplot(aes(x = p)) +
 # geom_histogram(bins = 50) +
#  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())

# flat on cloglog
pr5 <- tibble(prior = rskew_normal(1e6, mu=-0.59, sigma = 1.26, alpha = -4.20)) %>%  
  ggplot(aes(x = prior)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  annotate(geom="text", x=-3, y=60000, label="skew_N(-0.59,1.26,-4.20)",
              color="red", size=6) +
  theme(panel.grid = element_blank())

l5 <- tibble(log_odds = rskew_normal(1e6, mu=-0.59, sigma = 1.26, alpha = -4.20))%>%  
  mutate(p = logistic(log_odds)) %>% 
  ggplot(aes(x = p)) +
#  geom_histogram(bins = 50) +
#  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())

c5 <- tibble(cloglog_prob = rskew_normal(1e6, mu=-0.59, sigma = 1.26, alpha = -4.20)) %>% 
  mutate(p = invcloglog(cloglog_prob)) %>% 
  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())


# regu to invcloglog(0)
pr6 <- tibble(prior = rskew_normal(1e6, mu=-0.2, sigma = .7, alpha = -2.20)) %>%  
  ggplot(aes(x = prior)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  annotate(geom="text", x=-1, y=60000, label="skew_N(-0.2,.7,-2.20)",
              color="red", size=6) +
  theme(panel.grid = element_blank())

l6 <- tibble(log_odds = rskew_normal(1e6, mu=-0.2, sigma = .7, alpha = -2.20))%>%  
  mutate(p = logistic(log_odds)) %>% 
  ggplot(aes(x = p)) +
 # geom_histogram(bins = 50) +
#  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())

c6 <- tibble(cloglog_prob = rskew_normal(1e6, mu=-0.2, sigma = .7, alpha = -2.20)) %>% 
  mutate(p = invcloglog(cloglog_prob)) %>% 
  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  geom_vline(xintercept=invcloglog(0), color = "red") +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())



(l1 + pr1 + c1) / (l2 + pr2 + c2) / (l3 + pr3 + c3) / (l4 + pr4 + c4)/ (l5 + pr5 + c5) / (l6 + pr6 + c6)

```


```{r}
ggsave("figures/plot_of_priors.png", width=9, height=10,dpi=300)
```

The log-odds Normal(0,1) gently regularizes p towards .5, but still allows for stronger values. This might be a good prior to use for the beta parameters. 





N(0,4) make no sense for logit-hazard models.




Compare three standard deviations.

The log-odds Normal(0,1) gently regularizes p towards .5, but still allows for stronger values. This might be a good prior to use for the beta parameters. 


The alpha parameters tend to drift toward the lower end of the probability range in general (i.e., they are typically below .5 in hazard space, also for RT studies). The log-odds Normal(0, 1.5) prior is nearly flat in probability space, but it does still push the mass away from the boundaries.


```{r}
set.seed(11)

# generate draws from U(0,1)
dat <- 
  tibble(p = runif(1e5, 0, 1)) %>% 
  mutate(g = logit(p),
         c = cloglog(p)) 
# display
dat %>%   
  ggplot(aes(x = c)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())

plot(density(dat$c))

# fit models
fit11.11 <-
  brm(data = dat,
      family = student,
      g ~ 1,
      chains = 4, cores = 4,
      file = "models/fit11.11")


fit11.11b <-
  brm(data = dat,
      family = skew_normal(),
      c ~ 1,
      chains = 4, cores = 4,
      file = "models/fit11.11b")

fit11.11b2 <-
  brm(data = dat,
      family = student(),
      c ~ 1,
      chains = 4, cores = 4,
      file = "models/fit11.11b2")

```

```{r}
print(fit11.11)
print(fit11.11b)
print(fit11.11b2)


pp_check(fit11.11b)
```

Now we can reverse the process. Here’s what it would look like if we simulated from the Student  
t-distribution based on those posterior means and then converted the results into the probability metric.

```{r}
set.seed(11)


# cloglog
#library(sn)

tibble(c = rskew_normal(1e8, mu=-0.59, sigma = 1.26, alpha = -4.20) ) %>% # simulate from skew-normal #distribution !!!!!!!! for intercept 
#  !!!!!!!!!

#tibble(c = rsn(1e6, xi=-1, omega = 1, alpha = -2) ) %>% # simulate from skew-normal distribution
 
   mutate(p = invcloglog(c)) %>% 
  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())


```



# Set up priors, and fit the model with full random effects structure.

```{r priors}
priors <- c(
  set_prior("normal(0, 1)", class = "b"), # for beta parameters when using logit link
  
  #set_prior("skew_normal(-0.5, .95,-4)", class = "b"), # for beta parameters when using cloglog link
  
  set_prior("student_t(7.61, 0, 1.57)", class = "b", coef = "Intercept"), # flat prior for intercept on hazard scale when using logit link; 
  
  #set_prior("skew_normal(-1,1,-2)", class = "b", coef = "Intercept"),   # weakly regularizing prior for intercept when using cloglog link (hazard values below .5 more likely than values above .5)
  set_prior("normal(0, 1)", class = "sd"), # for standard deviation of RE
  set_prior("lkj(2)", class = "cor") # for correlations between RE
)

inv_cloglog <- function(c){
  1-exp(-exp(c))
}
cloglog <- function(p){
  log(-log(1-p))
}

dat <- 
  tibble(c1 = rnorm(1e5,0,1), # usa as weakly reguralizing prior for beta parameters (when using logit link)
         c2 = rt(1e5,7.61)* 1.57) %>% # use as weakly reguralizing prior for interceptparameter (when using logit 
  mutate(p1 = inv_logit_scaled(c1),
         p2 = inv_logit_scaled(c2)) 

plot(density(dat$c1))
plot(density(dat$c2))
plot(density(dat$p1))
plot(density(dat$p2))

# cloglog
dat2 <- tibble(c1 = rnorm(1e5,-1,1.1), # cloglog intercept
              c2 = rskew_normal(1e5, -0.5, sigma = .95, alpha = -4)) %>% # beta toward .6
 
  mutate(p1 = inv_cloglog(c1),
         p2 = inv_cloglog(c2)) 


plot(density(dat2$c1))
plot(density(dat2$c2))
plot(density(dat2$p1))
plot(density(dat2$p2))



```

```{r full-random-effects-model}
plan(multicore)

model_full_RE_newprior <-
   brm(data = ptb_data,
       family = binomial(link="cloglog"),
       event | trials(1) ~ 0 + Intercept + 
                           condition*period_9*trial_c + 
                           condition*I(period_9^2) + 
                           condition*I(period_9^3) +
                           (1 + condition*period_9*trial_c +
                           condition*I(period_9^2) +
                           condition*I(period_9^3) | pid),
       prior = priors,
       chains = 4, cores = 4, iter = 3000, warmup = 1000,
       control = list(adapt_delta = 0.999, step_size = 0.04, max_treedepth = 12),
       seed = 12, init = "0",
       file = "Tutorial_2_Bayesian/models/model_full_RE_newprior")

# the formula above comes down to the following effects:
# cloglog[h(t)]=Intercept+ ##the estimated cloglog[h(t)] in bin 9 for trial 1000 for reference condition "blank"
# period_9+I(period_9^2)+I(period_9^3)+ ##a cubic specification of TIME for reference condition "blank"
# congruent+congruent:period_9+congruent:I(period_9^2)+congruent:I(period_9^3)+ ##effect of congruent interacts cubicly with TIME
# incongruent+incongruent:period_9+incongruent:I(period_9^2)+incongruent:I(period_9^3)+ ##effect of incongruent interacts cubicly with TIME
# trial_c + trial_c:period_9 + ##linear effect of trial number in bin 9 can change linearly over TIME for "blank"
# trial_c:congruent + trial_c:incongruent + ##linear effect of trial number in bin 9 can differ for congruent and incongruent
# trial_c:congruent:period_9 + trial_c:incongruent:period_9 ##how the linear effect of trial number changes linearly over TIME can differ for congruent and incongruent
```

Model_full_RE took between 3 and 4 hours to run.

```{r check-model-full-RE}
summary(model_full_RE)
```

Fit a model that relaxes proportionality assumption.

```{r}
# remove unnecessary columns before fitting a model
ptb_data <- ptb_data %>% select(-c(trial_c)) # 12840 obs. of 4 variables
head(ptb_data,n=17)
summary(ptb_data)
```

```{r cubic-random-effects-model}
plan(multicore)

model_cubic_RE <-
   brm(data = ptb_data,
       family = binomial(link="cloglog"),
       event | trials(1) ~ 0 + Intercept + 
                           condition*period_9 + 
                           condition*I(period_9^2) + 
                           condition*I(period_9^3) +
                           (1 + condition*period_9 +
                           condition*I(period_9^2) +
                           condition*I(period_9^3) | pid),
       prior = priors,
       chains = 4, cores = 4, iter = 3000, warmup = 1000,
       control = list(adapt_delta = 0.999, step_size = 0.04, max_treedepth = 12),
       seed = 12, init = "0",
       file = "Tutorial_2_Bayesian/models/model_cubic_RE")

# the formula above comes down to the following effects:
# cloglog[h(t)]=Intercept+ ##the estimated cloglog[h(t)] in bin 9 for trial 1000 for reference condition "blank"
# period_9+I(period_9^2)+I(period_9^3)+ ##a cubic specification of TIME for reference condition "blank"
# congruent+congruent:period_9+congruent:I(period_9^2)+congruent:I(period_9^3)+ ##effect of congruent interacts cubicly with TIME
# incongruent+incongruent:period_9+incongruent:I(period_9^2)+incongruent:I(period_9^3) ##effect of incongruent interacts cubicly with TIME
```

```{r check-model-cubic-RE}
summary(model_cubic_RE)
```

#### relax all ass

```{r cubictime-quadtrial-model}
plan(multicore)

model_cubictime_quadtrial <-
   brm(data = ptb_data,
       family = binomial(link="cloglog"),
       event | trials(1) ~ 0 + Intercept + 
                           condition*period_9*trial_c + 
                           condition*period_9*I(trial_c^2) + 
                           condition*I(period_9^2)*trial_c + 
                           condition*I(period_9^2)*I(trial_c^2) +
                           condition*I(period_9^3) +
                      (1 + condition*period_9*trial_c +
                           condition*period_9*I(trial_c^2) +
                           condition*I(period_9^2)*trial_c +
                           condition*I(period_9^2)*I(trial_c^2) +
                           condition*I(period_9^3) | pid),
       prior = priors,
       chains = 4, cores = 4, iter = 3000, warmup = 1000,
       control = list(adapt_delta = 0.999, step_size = 0.04, max_treedepth = 12),
       seed = 12, init = "0",
       file = "Tutorial_2_Bayesian/models/model_cubictime_quadtrial")

# the formula above comes down to the following effects:
# cloglog[h(t)]=Intercept+ ##the estimated cloglog[h(t)] in bin 9 for trial 1000 for reference condition "blank"
# period_9+I(period_9^2)+I(period_9^3)+ ##a cubic specification of TIME for reference condition "blank"
# congruent+congruent:period_9+congruent:I(period_9^2)+congruent:I(period_9^3)+ ##effect of congruent interacts cubicly with TIME
# incongruent+incongruent:period_9+incongruent:I(period_9^2)+incongruent:I(period_9^3)+ ##effect of incongruent interacts cubicly with TIME
# trial_c + trial_c:period_9 + ##linear effect of trial number in bin 9 can change linearly over TIME for "blank"
# trial_c:congruent + trial_c:incongruent + ##linear effect of trial number in bin 9 can differ for congruent and incongruent
# trial_c:congruent:period_9 + trial_c:incongruent:period_9 ##how the linear effect of trial number changes linearly over TIME can differ for congruent and incongruent
```



# plot hazard functions

```{r}
model_full_RE <- readRDS("Tutorial_2_Bayesian/models/model_full_RE.rds") 
model_full_RE_newprior <- readRDS("Tutorial_2_Bayesian/models/model_full_RE_newprior.rds") 
fixef(model_full_RE)
fixef(model_full_RE_newprior)
```


# visualize posterior distributions of the effects of congruent and incongruent primes on hazard relative to blank prime, for each time bin in trial 1000, and for each time bin in trial 100.

```{r load-model}
model_full_RE <- readRDS("Tutorial_2_Bayesian/models/model_full_RE.rds") 
```

```{r make-plot-effects}
post <-as_draws_df(model_full_RE) %>% # 8000 draws x 299 variables
   select(starts_with("b_")) %>%       # 8000 x 18
   expand_grid(period_9 = -3:6) %>%   
   mutate(period_9sq = period_9^2,
          period_9cu = period_9^3,
          trial100 = -900/1000)  
# effects for trial 1000
p1congruent <- post %>% 
  mutate(postdistr = b_conditioncongruent + period_9 * `b_conditioncongruent:period_9` + period_9sq * `b_conditioncongruent:Iperiod_9E2` + period_9cu * `b_conditioncongruent:Iperiod_9E3`) %>%
  group_by(period_9) %>%
  
  ggplot(aes(x = period_9, y = postdistr)) +
  stat_lineribbon(show.legend=F) +
  scale_fill_brewer() +
  geom_hline(yintercept=0, linetype="dashed", color = "red") +
  scale_x_continuous(breaks = c(-3:6), labels=c(((-3:6)+9)*40),
                     limits = c(-3,6)) +
  scale_y_continuous(breaks = c(-6,-4,-2,0,2,4,6), limits = c(-6,6)) +
  labs(title = "trial 1000", x = "time bin", y = "effect of congruent") +
  theme(panel.grid = element_blank(),
        axis.text.x = element_text(angle=90)) 

p2incongruent <- post %>% 
  mutate(postdistr = b_conditionincongruent + period_9 * `b_conditionincongruent:period_9` + period_9sq * `b_conditionincongruent:Iperiod_9E2` + period_9cu * `b_conditionincongruent:Iperiod_9E3`) %>%
  group_by(period_9) %>%
  
  ggplot(aes(x = period_9, y = postdistr)) +
  stat_lineribbon(show.legend=F) +
  scale_fill_brewer() +
  geom_hline(yintercept=0, linetype="dashed", color = "red") +
  scale_x_continuous(breaks = c(-3:6), labels=c(((-3:6)+9)*40),
                     limits = c(-3,6)) +
  scale_y_continuous(breaks = c(-6,-4,-2,0,2,4,6), limits = c(-6,6)) +
  labs(x = "time bin", y = "effect of incongruent") +
  theme(panel.grid = element_blank(),
        axis.text.x = element_text(angle=90)) 






p1congruent + p2incongruent
#(p1+p2+p3)/(p4+p5+p6)/(p7+p8+p9)/(p10+p11+p12)/(p13+p14+p15)
```

```{r save-plot-effects}
ggsave("figures/effects_knot_1.png", width = 12, height = 16, dpi = 600)

```


